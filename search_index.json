[
["index.html", "Spatial Statistics for Stream Networks Preface Software Authors Acknowledgments", " Spatial Statistics for Stream Networks Jay M. Ver Hoef, Erin E. Peterson, Daniel J. Isaak 2018-12-03 Preface This book is a result of a long collaboration among the three of us. Our journey began at the Holiday Inn Express on the River in Corvallis, Oregon, in August of 2003. Jay was on a review committee for the EPA STARMAP grant to Oregon State University and Colorado State University. Erin was working on her Ph.D. with Dave Theobald at Colorado State University, and they were doing research on the grant. Erin and Dave had presented some of their research. Later, some of us who had travelled to Corvallis, were on the deck of the Holiday Inn overlooking the Willamette River, relaxing with a drink. Erin and Dave posed the question to Jay, “We would like to do kriging on streams, but use stream distance, rather than Euclidean distance. Is it possible?” Jay had used spatial moving averages in several previous publications to develop flexible spatial covariance models (Barry and Ver Hoef 1996), and for multivariable models (Ver Hoef and Barry 1998). These models have also been called process convolutions (Higdon 1998). Jay had thought about the possibility of using these models on other topologies, even specifically for stream networks. However, the task of getting data into a Geographical Information System (GIS), and extracting the necessary information, was daunting, and he had no one pressing him with a real application. Erin and Dave provided the necessary push, and they had extensive GIS experience. The collaboration was initiated. About a year later, Jay taught a course on Spatial Statistics with Noel Cressie in Switzerland. While soaking in the spa at Yverdon les Bains, Jay explained his work on stream networks to Noel. Noel then worked with his colleagues, specifically Bronwyn Harch, and used these ideas for some research they had on stream networks in Australia. The two seminal papers appeared (Ver Hoef, Peterson, and Theobald 2006; Cressie et al. 2006). After finishing her Ph.D., Erin was hired by Bronwyn Harch and worked at CSIRO in Brisbane, Australia. Erin and Jay continued to collaborate on a series of papers (Peterson, Theobald, and Ver Hoef 2007; Peterson and Ver Hoef 2010), and a full theory that included tail-up, tail-down, and Euclidean distance (classical geostatistical models) in a mixed model framework was presented as a discussion paper in a Journal of the American Statistical Association paper (Ver Hoef and Peterson 2010b), with comments by Cressie and O’Donnell (2010) and Sahu (2010) and a rejoinder (Ver Hoef and Peterson 2010a). During this time, Dan learned of these methods, and contacted Erin and Jay. Geostatistics has a long history of modeling air temperature, and Erin worked with Dan to produce a seminal paper on geostatistical modeling for stream temperature data (Isaak et al. 2010). It soon became apparent that in order for these models to be generally useful, software was needed to integrate GIS operations with statistical computing. A watershed event occurred with a working group at the National Center for Ecological Analysis and Synthesis (NCEAS) in Santa Barbara, with help from Deputy Director Stephanie Hampton and generous support from Chris Jordan, NOAA Fisheries. Erin, Jay, and Dan realized that software, along with a broad base of users, was needed to really launch the methods. The NCEAS working group resulted in GIS software (Peterson and Ver Hoef 2014), R software, (Ver Hoef et al. 2014), and three applied papers show-casing the methods (Peterson et al. 2013; Isaak et al. 2014; Som et al. 2014). Since then, we have taught courses based on the methods and software at least once a year. We continued the mapping of stream temperature throughout the western U.S. (D. J. Isaak, Wenger, et al. 2017), and created layers for download and an interactive viewer https://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST.html We also created a “National Stream Internet,” https://www.fs.fed.us/rm/boise/AWAE/projects/NationalStreamInternet.html where we have taken all of the streams in the continental U.S., starting with the National Hydrography Database (NHD), and conditioned them so that they work with our models. We are trying to keep a bibliography of applications. This book has grown from our desire to make these models as accessible as possible. It has been a fun journey. We enjoy working together, and making new colleagues along the way. Jay, Erin, and Dan Software The SSN package can be installed from CRAN. In an R terminal type install.packages(&quot;SSN&quot;) Authors Jay Ver Hoef is a senior scientist and statistician for the Marine Mammal Lab, part of the Alaska Fisheries Science Center of NOAA Fisheries, U.S. Dept. of Commerce. He works for a U.S. Government research lab where he develops statistical methods and consults on a wide variety of topics related to marine mammals and stream networks. The Marine Mammal Lab is located in Seattle, Washington, although Jay lives in Fairbanks, Alaska. His main statistical interests are in spatial statistics and Bayesian statistics, especially applied to ecological and environmental data. Erin Peterson … Dan Isaak … Acknowledgments We would like to thank… References "],
["intro.html", "Chapter 1 Introduction 1.1 Motivating Example 1.2 Why Stream Network Models?", " Chapter 1 Introduction caption, .caption{ font-style:italic; margin-top:0.5em; margin-bottom:0.5em; width:99%; text-align: left; } body{ font-family: Times-Roman; font-size: 11pt; } p {line-height: 2em;} tr:nth-child(even) {background-color: #f2f2f2;} th { background-color: #4CAF50; color: black; } p { padding-bottom: 15px; } Spatial statistical models are broadly applied within the fields of geology, geography, ecology, real estate, and medicine, just to name a few. Spatial statistical models often have two broad goals: 1) to describe how covariates affect a response variable, and 2) to make predictions at unsampled locations. For example, data might be used to fit a model establishing a relationship between elevation and air temperature, and also to make a map of air temperature based on a dense set of predictions. When fitting the model and making predictions, a spatial statistical model uses a covariance matrix composed of autocovariance values that rely on Euclidean distances (from straight lines in two dimensions) among all sites. Distances for stream networks, however, are poorly represented by Euclidean distances because fish and water quality attributes do not move over land but follow the sinuous pattern of the network. To apply traditional spatial statistical modeling techniques, those distances must be accurately represented in a covariance matrix structure for stream networks. This chapter provides an overview of recent research on this topic and a new class of spatial-stream network (SSN) model that is being used for an increasing number of applications. Ver Hoef, Peterson, and Theobald (2006) and Cressie et al. (2006) initially described new models for stream networks based on moving average constructions. The models used stream distance, which was defined as the shortest distance between two locations computed only along the stream network. (Peterson, Theobald, and Ver Hoef 2007) provide in-depth discussion on the statistical and ecological consequences of substituting stream distance measures for Euclidean distance. The original work defined a class where the moving average function was termed “tail-up,” and further models with a “tail-down” moving average function were described by (Ver Hoef and Peterson 2010b), and we give further details below. Both types of models were necessary to cover a range of autocorrelation possibilities, so a variance component approach, combining tail-up, tail-down, and classical geostatistical models based on Euclidean distance, was promoted in Garreta, Monestiez, and Ver Hoef (2009), Peterson and Ver Hoef (2010) and Ver Hoef and Peterson (2010b). Although SSN models are most often used for streams, they can be generalized to other dendritic networks (Peterson et al. 2013). Because each stream topology is unique, prior to fitting the SSN models, data are preprocessed to develop distance and weighting matrices in a geographical information system (GIS) using the STARS (Spatial Tools for the Analysis of River Systems) custom toolset (Peterson and Ver Hoef 2014}) for ArcGIS (ESRI 2014). STARS produces the spatial, topological, and attribute information needed to fit a SSN model using the SSN package (Ver Hoef et al. 2014) with the R statistical software (R Core Team 2015). New spatial statistical methods were recently developed to fit models to data collected on stream (river) networks (Ver Hoef and Peterson 2010b). Stream networks, in our usage, are based on a mathematical topology that represents streams as line segments that converge downstream, or viewed conversely, that create dichotomous branching when moving upstream from an outlet (the most downstream location in the network). A number of packages (including, but not limited to, geoR (Ribeiro and Diggle 2001), spatial (Venables and Ripley 2002), geoRglm (Christensen and Ribeiro 2002), gstat (Pebesma 2004}), fields (Fields Development Team 2006), spBayes (Finley, Banerjee, and Carlin 2007), and ramps (Smith, Yan, and Cowles 2008)) have been written in R to fit spatial statistical models that use geostatistical autocovariance functions (based on Euclidean distance), but they are not guaranteed to produce positive-definite covariance matrices when using an alternative distance measure, such as stream distance (Ver Hoef, Peterson, and Theobald 2006). In this book, we present the R package SSN, which allows users to fit autocovariance functions developed for stream networks (Ver Hoef and Peterson 2010b). These models are unique because they use distance measured along the network, they incorporate flow direction, and they allow covariance weighting when segments converge (e.g., by volume of flowing water). We develop two classes of covariance models based on moving average constructions that we call the tail-up and tail-down models. These models may also be combined in a mixed model strategy that includes models based on Euclidean distance. Such geostatistical mixed models are important because they can account for multiple processes of spatial autocorrelation in stream systems, including those that occur within the stream and others that result from the straight-line distances due to the terrestrial environment (Ver Hoef and Peterson 2010b). 1.1 Motivating Example Organisms that live in streams and rivers are ectothermic and so temperature profoundly affects their ecology. Concerns about climate change and habitat alteration that degrade thermal environments have led to extensive stream temperature monitoring in previous decades by dozens of natural resources agencies throughout North American and Europe. In the American West, the NorWeST (Northwest Stream Temperature) project has aggregated and organized, from $&gt;$100 natural resource agencies, most of the digital temperature records collected using miniature sensors into a massive online database http://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST.html The database hosts $&gt;$200 million hourly temperature recordings measured at $&gt;$20,000 unique stream sites. SSN models have been used with a subset of the data to create prediction maps and develop a consistent set of high-resolution climate scenarios. The project is on-going, but prediction map scenarios at a 1-km resolution have been developed for $&gt;$500,000 kilometers of streams and rivers 1.1. Detailed maps of higher resolution are available for download, and an interactive map that allows zooming and panning are available at the NorWeST website. Figure 1.1: a) Locations of temperature records measured with sensors at $&gt;$20,000 unique stream sites in the NorWeST database, where the blue lines are streams, and the solid black circles are locations. b) Mean August temperature predictions throughout most of the western United States using methods described in this book. Based on leave-one-out crossvalidation there was an \\(r^2\\) of 0.90 between true and predicted temperature values at observed sites, with a root-mean-squared prediction error (RMSPE) of 1.0\\(^0\\)C across all streams. The accuracy of the SSN temperature model used to develop the scenarios, and the model’s ability to extract reliable information from large, non-random datasets collected by the management community, has led to the rapid adoption and broad use of NorWeST scenarios for conservation planning. The scenarios have been used to precisely identify climate refugia for cold-water fishes such as trout and char (Isaak et al. 2015, 2016), characterize thermal niches of fish and amphibian species (Al-Chokhachy et al. 2016; D. J. Isaak, Wenger, and Young 2017), describe how salmon migrations are affected by temperature (Westley et al. 2015), and estimate the distribution and abundance of fish populations (Dauwalter, Fesenmyer, and Bjork 2015; D. J. Isaak, Ver Hoef, et al. 2017). To illustrate statistical methods for stream networks in this Chapter, we use a very small subset of the NorWeST data. The stream network and sampling locations for the example are shown in Figure 1.2 Figure 1.2: The study area in central Idaho, where average August temperature data were collected from the Middle Fork of the Salmon River in 2004. The sample locations are shown as solid black circles. 1.2 Why Stream Network Models? Many researchers have called for using stream distance, rather than Euclidean distance, when developing spatial statistical models for stream networks (Dent and Grimm 1999; Torgersen, Gresswell, and Bateman 2004; Yuan 2004). There is a problem, however, if we simply use stream distance, rather than Euclidean distance, in a standard geostatistical autocovariance model (e.g., a large number geostatistical models based on Euclidean distance can be found in Chiles and Delfiner 1999, 80–97). To illustrate, we computed stream distances between all pairs of stream locations shown in Figure 1.2, and then used stream distances (rather than Euclidean distances) in five commonly-used autocovariance models from geostatistics. For all 5 models, the “nugget” effect was set to zero and the “partial sill” was set to 1. The parameter that controls the amount of autocorrelation, often called the “range,” was allowed to vary. For each value of the range for each model, a spatial covariance matrix was determined based on stream distance among the 90 locations in Figure 1.2. The minimum eigenvalue as a function of the range is shown in Figure 1.3. Figure 1.3: Minimum eigenvalues of spatial covariance matrices for classic geostatistical models based on Euclidean distances, for various range parameters (in log base 2 meters), but when using using stream distance, rather than Euclidean distance, among all locations shown in the Study Area Figure Notice that negative eigenvalues mean that the covariance matrix is not positive definite, and hence not valid. Figure 1.3 demonstrates that the linear-with-sill, rational quadratic, and Gaussian models are not valid when using stream distance for this data set for certain range values. This illustrates that simple substitution of stream network distance for Euclidean distance does not guarantee valid models, in the sense that the covariance matrix is not guaranteed to be positive definite. Even when a model appears to be valid for all range values for a given data set, such as the exponential or spherical models in Figure 1.3, there is no guarantee that additional points, e.g. for prediction purposes, will keep covariance matrices positive definite. Similarly, a change in network configuration could cause these models to fail; indeed, Ver Hoef, Peterson, and Theobald (2006) show a network where the spherical model has negative eigenvalues. Despite this, some researchers continue to erroneously substitute network distance into models designed for geostatistics. Thus, in order to use stream distance rather than Euclidean distance, another approach is indicated. Even though substituting stream distance for Euclidean distance does not guarantee valid models, it is fair to ask why use stream distance at all? Fitting SSN models requires more effort than fitting standard geostatistical methods. Calculating stream distances, and weighting stream segments (as we will describe below) requires considerable GIS computation, whereas Euclidean distance can be readily calculated in R (or any software) without a GIS. What is gained by the stream network models? Consider a simple example using the data in Figure 1.2. We withheld one measurement, the open circle in Figure 1.4, which also shows its two closest locations (solid circles). Figure 1.4: A comparison of ordinary kriging predictions, using a covariance matrix based on Euclidean distance, and predictions from a stream network model, using a covariance matrix based on stream distance and flow information. The values at the solid circles are used as observed data to predict the value at the open circle. The real value at the open circle is given, along with predictions for the two models with 90% prediction invervals. We predicted the withheld observation using ordinary kriging (Cressie 1993) based on Euclidean distance, and also predicted it based on a stream-network model (Ver Hoef and Peterson 2010b) that we will discuss in greater detail below. Ordinary kriging, based on Euclidean distance, predicted a value for the withheld location of 13.1\\(^{\\circ}\\)C, with a 90% prediction interval of \\(\\pm\\) 2.74\\(^{\\circ}\\)C. A tail-up stream-network model predicted a lower value of 9.4\\(^0\\)C, with a prediction interval of \\(\\pm\\) 1.75\\(^{\\circ}\\)C. Both intervals capture the true value, but the stream network prediction is more accurate. However, there is more of interest. Recall that ordinary kriging generally weights nearby locations most heavily, and the prediction, 13.1, is somewhere between observed values 12.3 and 15.0. From this perspective, the Euclidean model produces a sensible prediction (Figure 1.4). Yet, this is not logically consistent for a flowing stream. Notice that the temperature decreased from 15.0\\(^{\\circ}\\)C to 12.3\\(^{\\circ}\\)C downstream between the two observed locations on the main stream segment (thicker line), even though temperature generally increases while going downstream. This suggests that the unobserved tributary added cold water, causing the drop in temperature. Logically, the downstream temperature of 12.3\\(^{\\circ}\\)C should be some weighted average of temperatures from the two upstream segments; one with a temperature of 15.0\\(^{\\circ}\\)C, and while the other temperature is unknown, it is surely less than 12.3\\(^{\\circ}\\)C. Thus, the ordinary kriging estimate of 13.1\\(^{\\circ}\\)C is not logically consistent, whereas the estimate from the stream-network model, 9.4\\(^{\\circ}\\)C, is logically consistent. Although this is but a single prediction, we have observed this type of difference between ordinary kriging and stream network model predictions on many occasions, where the stream network model tends to reflect the topological constraints and the effect of flow on correlation structure. A similar example is given by Peterson et al. (2013). References "],
["topology-and-distance.html", "Chapter 2 Topology and Distance 2.1 Stream Topology 2.2 Dual Coordinate Systems 2.3 Stream Distance 2.4 Additive Function", " Chapter 2 Topology and Distance caption, .caption{ font-style:italic; margin-top:0.5em; margin-bottom:0.5em; width:99%; text-align: left; } body{ font-family: Times-Roman; font-size: 11pt; } p {line-height: 2em;} tr:nth-child(even) {background-color: #f2f2f2;} th { background-color: #4CAF50; color: black; } p { padding-bottom: 15px; } 2.1 Stream Topology We define stream segments as lines between junctions in a stream network . Our convention is that a location downstream is assigned a lower real number for position than a location upstream. A dendritic stream network has a single most-downstream point (the outlet), which we set to 0, and it is the point from which all distances are computed. We define “distance upstream” to be the length of the line from any location on a stream network that can be connected by a continuous line to the network outlet (lowest point in that network). For model development it will be convenient to extend all terminal upstream segments to \\(\\infty\\) and a line downstream of the outlet to \\(-\\infty\\). There are a finite number of stream segments in an SSN, and we index them arbitrarily with \\(i = 1,2,\\ldots\\). Many locations will have the same distance from the outlet (our 0 point) in an SSN, so to uniquely define locations using distance upstream, we denote locations as \\(x_i\\), where \\(x\\) is distance upstream and \\(i\\) indicates that it is on the \\(i\\)th stream segment. In Figure 2.1, \\(r_1\\) is distance \\(r\\) upstream and it is located on the segment labeled 1. Note the arbitrary labeling of segments \\(r_1\\), \\(s_2\\), and \\(t_3\\) as seen in Figure 2.1. We use \\(l_i\\) for the smallest, and \\(u_i\\) for the largest, upstream distance on the \\(i\\)th segment (Figure 2.1). Figure 2.1: Three locations on a stream network, \\(r_1\\), \\(s_2\\), \\(t_3\\). The location of the farthest upstream distance on segment 1 is \\(u_1\\). The locations of the farthest downstream distances on segments 2 and 3 are \\(l_2\\) and \\(l_3\\), respectively. Effectively, \\(u_1 = l_2 = l_3\\), but it is convenient to use the distinct notation. For FU sites (\\(s_2\\) and \\(t_3\\)), \\(a\\) is used for the shorter distance to their common junction, and \\(b\\) is used for the longer distance. When sites are FC (\\(s_2\\) and \\(r_1\\)), \\(h\\) is used to denote the distance between them. Let \\(A\\) be the set of all stream segment indices. We denote \\(U_{i}\\), a subset of \\(A\\), as the set of stream segments upstream of \\(x_i\\), including the \\(i\\)th segment, and we denote \\(U^{*}_{i}\\) as the set excluding the \\(i\\)th segment. We denote \\(D_{i}\\), also a subset of \\(A\\), as the set of stream segments downstream of \\(x_i\\), including the \\(i\\)th segment, and we denote \\(D^{*}_{i}\\) as the set excluding the \\(i\\)th segment. This notation make precise the definition of “flow-connected” (FC) for two locations, \\(r_i\\) and \\(s_j\\), if \\(U_i \\cap U_j \\neq \\emptyset\\), and they are “flow-unconnected” (FU) if \\(U_i \\cap U_j = \\emptyset\\). We can also define the set of stream segments “between” two FC locations, \\(r_i \\leq s_j\\), exclusive of the \\(i\\)th and \\(j\\)th segments, as \\(D^{*}_{j} \\setminus D_i\\). For point locations, we use \\(\\vee_s\\) to denote the network only upstream of point \\(s\\), including all branchings, and \\(\\wedge_s\\) to denote the network downstream of \\(s\\) that follows flow only (i.e., it does not go downstream and then back upstream). Modeling covariance requires total stream distance between pairs of points, so for two FU locations we will use \\(a\\) to indicate the shorter distance from one location to the nearest junction downstream that shares flow with the other location (2.1), and we use \\(b\\) to indicate the longer distance to the same junction. We use \\(h\\) for the distance between two FC locations (Figure 2.1). 2.1.1 Streams in R The spatial data needed to fit a stream network model are non-trivial. Much of the spatial data editing, information generation, and formatting take place in ArcGIS using the Spatial Tools for the Analysis of River Systems STARS toolset (Peterson and Ver Hoef 2014). When this pre-processing is complete, a new directory is created to store the data, hereafter referred to as the .ssn directory, which can then be imported into R. These data include the feature geometry, attribute data, and topological relationships of each point and line data set, see Figure 2.2. Figure 2.2: The .ssn directory contains the spatial, attribute, and topological information needed to create a SpatialStreamNetwork object in R. The .shp files are of stream reaches (edges.shp), observed points on the stream (site.shp), and prediction points on the stream (preds.shp)(optional). The .dat files contain topological relationship information for each distinct network; in this example, there are 5 networks.. The .ssn directory will always contain two shapefiles: edges and sites, which contain the geometry and attribute information for the stream network and the observed data locations. Multiple comma-delimited text files containing the topological information for each stream network within the edges data set will also be included. Here, a network is defined as a set of connected, directed line segments that share a common junction somewhere downstream. Note that the naming conventions for these files are implemented by the STARS toolset and must be preserved. Multiple shapefiles representing the prediction locations may also be included in the .ssn directory; however, the naming conventions for these data sets will vary. Peterson and Ver Hoef (2014) provide a detailed description of the STARS toolset, the methods used to generate the .ssn directory, and data therein. The SpatialStreamNetwork class is an S4 object (Figure 2.3, which is the foundational spatial data class in the SSN package. Its structure adheres to the conventions for spatial data classes set out by Bivand, Pebesma, and Gomez-Rubio (2008). Yet, the SpatialStreamNetwork is unique because it contains both point and line features within the same S4 object. It directly extends class SpatialLinesDataFrame, with additional slots included to store the spatial point data SSNPoints, a matrix containing information about the network coordinates of each line segment network.line.coords, as well as a string representing the filepath to the .ssn directory. A new class, SSNPoint, has been defined and created to store spatial point data for observation and prediction locations. This class is similar to class SpatialPointsDataFrame, but is not a direct extension of it since common slot names contain the prefix “point.” An additional matrix containing network coordinates, network.point.coords, has also been included. The object SSNPoints is a list of class SSNPoints that stores objects of class SSNPoint. It also contains a slot named ID, which holds a string identifier for each SSNPoint object. This allows identification within the SpatialStreamNetwork object when multiple data sets of prediction sites are included. Figure 2.3: The SpatialStreamNetwork class and slots; arrows with small heads show sub-class extensions and arrows with large heads show the inclusion of lists of objects. 2.2 Dual Coordinate Systems While it is desirable to build models using stream distance, generating measures of distance is more complex in a SSN model than a model based on Euclidean distance. Stream network data have a dual spatial coordinate system because streams are embedded within the terrestrial landscape they flow through. As a result, points within a stream are located in 2-D space (geographical location), as well as within the network (topological location) (Figure 2.4. Although models based on either Euclidean distance or network distance may be simpler to implement, critical information about environmental or ecological processes and correlation structures may be lost when models do not adequately account for the dual coordinate system (Schlosser and Angermeier 1995; Urban and Keitt 2001; Fausch et al. 2002; Benda et al. 2004; Urban et al. 2009; Dale and Fortin 2010; Peterson et al. 2013). Therefore, we will promote combining classical geostatistical models with those developed for stream networks. The details are given below. First, we give some preliminaries on notation and computing distance within networks, as these are less familiar than typical 2-D coordinate systems and computing Euclidean distance. Figure 2.4: Locations within a stream network are characterized by a dual spatial coordinate system. Three locations are given by solid and open circles and a grey square. In (a) and (b) the 3 locations have exactly the same 2-D coordinates, although their positions (and distances from each other) within the two stream networks are different. In (a) and (c) the 3 locations have exactly the same positions (and distances from each other) within the network, although their 2-D coordinates are different. 2.3 Stream Distance In general, a straightforward approach for keeping track of network structure in a directed graph, such as a stream network, is to label segments (we adopt the graph terminology “edge”). A ForwardStar data structure (Ahuja, Magnanti, and Orlin 1993) is commonly used to keep track of which edge leads to another edge. This data structure is based on a set of “to-from” tables, which store information about the coincidence of features and can be searched to generate new spatial information. However, traversing to-from tables generated from a large stream network is computationally intensive, especially in an interpreted programming language like R. As an alternative, we developed a system based on a binary identifier (ID), which is used to rapidly assess flow-connectivity and stream distance between any two locations on the dendritic stream network. The process of assigning binary IDs is conceptually simple. First, the outlet edge (i.e., the most downstream edge in the network) is identified and assigned a binary ID equal to 1 (Figure 2.5). The information stored in the to-from table is then used to identify edges that are directly upstream from the outlet edge. Binary IDs are assigned to the upstream edge(s) by arbitrarily appending a 0 or 1 to the downstream binary ID. For example, binary IDs 10 and 11 are directly upstream from binary ID 1 in Figure 2.5. This process of moving upstream and assigning binary IDs continues until every edge in the stream network has been assigned a binary ID. Note that the binary ID is only unique within a stream network. Also, the binary ID is not the binary number that is equivalent to the segment number. Stream segments are numbered arbitrarily and sequentially, but binary IDs actually represent the branching structure. Figure 2.5: A binary identifier (ID) is assigned to each segment in a stream network. Use of binary IDs allows rapid assessment of flow-connectedness, distance to junctions, and stream distance among points on the network. The binary IDs are useful because they provide a way to rapidly determine whether locations have an FC or FU relationship. Two locations are considered FC when water flows from an upstream location to a downstream location. In contrast, two locations are FU when they reside on the same network, but water does not flow between them. In Figure 2.5, site \\(r_1\\) resides on the most downstream segment in the network (segment 1). Thus, the binary ID for \\(r_1\\) is completely nested within the binary ID for the edge containing site \\(s_3\\) (“1” is nested within “110”), which indicates that the two locations are FC. If the binary IDs for two edges are not nested, as is the case for \\(s_3\\) and \\(t_6\\) (“110” is not nested within “1111”), the two locations are FU. In addition, the binary IDs for FU locations contain information about the closest common downstream location. As an example, the most common downstream junction between sites \\(s_3\\) and \\(t_6\\) is “11” (Figure 2.5) and so “11” is the binary ID of the stream segment where sites \\(s_3\\) and \\(t_6\\) diverge. One of the advantages of SSN models is that they can be used to represent both FC and FU relationships within a stream network. In order to do this, information about directional relationships must be preserved within an asymmetric distance matrix, which contains the downstream-only distance between each pair of locations. Four pieces of spatial information are generated using the STARS toolset and subsequently used to calculate the downstream-only stream distance matrix: 1) the network ID, 2) the binary IDs, 3) the upstream distance from the network outlet to the most upstream location on each edge, \\(u_i\\) and 4) the upstream distance from the outlet to each location, \\(x_i\\). As mentioned previously, the binary IDs are only unique within a network and so the first step is to determine whether two locations reside on the same network using the network IDs. When this is true, the binary IDs are used to determine whether two locations are FC or FU. If they are FU, the downstream-only distance between \\(t_3\\) and \\(s_2\\) (Figure 2.1), \\(a\\), is \\(t_3 - u_1\\), while the downstream-only distance between \\(s_2\\) and \\(t_3\\), \\(b\\), is \\(s_2 - u_1\\). For FC sites, again determined by the binary IDs, the downstream-only distance from \\(s_2\\) to \\(r_1\\) is \\(s_2-r_1&gt;0\\), while \\(r_1-s_2=0\\). In fact, for any set of \\(n\\) locations, the directional distances can be stored in an asymmetric \\(n \\times n\\) matrix, which stores the distance to the common junction. In addition, the total stream distance between locations is generated by adding the transpose of the \\(n \\times n\\) matrix, to itself. Thus, everything required to construct the models described below is contained in this asymmetric matrix. 2.4 Additive Function Let \\(\\Omega(x)\\) be an additive function on a stream network; that is, \\(\\Omega(x)\\) is constant within a stream segment, but then \\(\\Omega(x)\\) is the sum of each segment’s value when two segments join at a junction. (Figure 2.6). Figure 2.6: The additive function. References "],
["ChapMA.html", "Chapter 3 Models for Autocorrelation 3.1 Discrete Time Series 3.2 Continuous Time Series 3.3 Tail-up Models 3.4 Tail-Down Models 3.5 Euclidean Distance Models", " Chapter 3 Models for Autocorrelation caption, .caption{ font-style:italic; margin-top:0.5em; margin-bottom:0.5em; width:99%; text-align: left; } body{ font-family: Times-Roman; font-size: 11pt; } p {line-height: 2em;} tr:nth-child(even) {background-color: #f2f2f2;} th { background-color: #4CAF50; color: black; } p { padding-bottom: 15px; } For stream networks, we originally called our constructions spatial moving-average models because they are analagous to moving average models in time series. They have also been called process convolution models. We review moving average models for time series to make the connection clear. 3.1 Discrete Time Series We start with the simplest case, and that which is most often used in time series; the discrete case (random variables defined on the set of integers). Then, we move to the case of continuous time. 3.1.1 Definition and Construction Let \\(W_i\\) be a random variable at integer \\(i\\). A moving average is created by “smoothing,” or averaging, the \\(W_i\\). One approach smoothes the trailing \\(\\theta\\) variables, or those that came earlier in time, \\[\\begin{equation} Z_i = \\frac{1}{\\theta}\\sum_{i-\\theta+1}^i W_i \\tag{3.1} \\end{equation}\\] Let’s create some random variables from moving averages in R, using \\(\\theta = 5\\). # set random number seed so reproducible set.seed(1001) # set number of independent random variables N = 20 # create independent random variables W = rnorm(N) # set length of moving average theta = 5 # create an empty vector to hold newly created variables Z = rep(NA, times = 20 - theta + 1) # create moving averages for(i in theta:N) Z[i - theta + 1] = mean(W[(i - theta + 1):i]) A plot of both \\(W_i\\) and \\(Z_i\\) is given in Figure 3.1. Figure 3.1: Creating moving average random variables, \\(Z_i\\) (black circles), by averaging independent random variables, \\(W_i\\) (gray circles). Notice that the moving-average random variables, in black, are autocorrelated. By autocorrelated, we mean that when \\(Z_i\\) and \\(Z_j\\) that are closer together, they are generally more similar than if they are farther apart. Basically, we are taking random variables that are independent, the \\(W\\)’s, and, by smoothing them, creating autocorrelation. The autocorrelation occurs because the constructed random variables, \\(Z\\)’s, can share the same underlying \\(W\\)’s, and the closer the \\(Z\\)’s are, the more \\(W\\)’s they have in common. In R, we compute the autocorrelation function for a long time series and compute the empirical autocorrelation function. # set random number seed so reproducible set.seed(1001) # set number of independent random variables N = 1000 # create independent random variables W = rnorm(N) # set length of moving average theta = 5 # create an empty vector to hold newly created variables Z = rep(NA, times = 20 - theta + 1) # create moving averages for(i in theta:N) Z[i - theta + 1] = mean(W[(i - theta + 1):i]) plot(acf(W)) plot(acf(Z)) Figure 3.2: Empirical autocorrelation function for \\(\\{Z_i\\}\\). The empirical autocorrelation function shows that autocorrelation drops to zero at distance \\(\\theta\\) and beyond because the constructed random variables do not share any \\(W\\)’s. Another way to write (3.1) is \\[ Z_i = \\sum_{i - \\theta + 1}^i \\omega_i W_i, \\] where \\(\\omega_i\\) is the weight \\(1/\\theta\\). More generally, we can think of the weights \\(\\omega_i\\) as a function on the integers from \\((-\\theta + 1)\\) to \\(0\\), and \\(0\\) outside of those limits, \\[\\begin{equation} g(j;\\theta) = \\omega_j \\mathcal{I}(-\\theta &lt; j \\le 0), \\tag{3.2} \\end{equation}\\] for \\(j \\in \\mathbb{Z}\\), where \\(\\mathbb{Z}\\) are the integers and \\(\\mathcal{I}(a)\\) is the indicator function, equal to 1 if its argument \\(a\\) is true, otherwise it is \\(0\\). Note that \\(g(j;\\theta)\\) is defined on all integers, but \\(g(j;\\theta)\\) sets the values to \\(0\\) outside of the range \\(0\\) to \\(-\\theta\\), which is convenient because we do not need to specify limits in the following, \\[\\begin{equation} Z_i = \\sum_{-\\infty}^\\infty g(j - i; \\theta) W_i. \\tag{3.3} \\end{equation}\\] If \\(\\omega_j = 1/\\theta\\) in \\(g(j;\\theta)\\), then (3.3) is exactly equal to (3.1). We write it this way because it will help clarify the connection to continuous time, and ultimately stream networks, in the next few sections. The function \\(g(j;\\theta)\\) can be made quite flexible. Already, \\(\\theta\\) is a parameter that controls the range of autocorrelation, but we can allow \\(\\omega_j\\) in \\(g(j;\\theta)\\) to vary in some way. Let \\[\\begin{align} g_\\ell(j;\\theta) &amp;= \\frac{1}{\\theta} \\mathcal{I}(-\\theta &lt; j \\le 0) \\\\ g_s(j;\\theta) &amp;= \\left(1-\\frac{|j|}{\\theta}\\right) \\mathcal{I}(-\\theta &lt; j \\le 0) \\tag{3.4} \\end{align}\\] Some R code to explore is given below, where we implement \\(g_s(j;\\theta)\\) in (3.4). # set random number seed so reproducible set.seed(1015) # moving average function g_s = function(j, theta){(1-abs(j)/theta)*(-theta &lt;= j &amp; j &lt;= 0)} #set theta theta = 10 # set number of independent random variables N = 40 # create independent random variables W = rnorm(N) # create autocorrelated random variables Z. Because of trailing weights, # (defined only for non-positive j), first Z_i is at theta Z = rep(NA, times = N) for(i in theta:N) Z[i] = sum(g_s((1:N)-i, theta)*W) The results are plotted (Figure 3.3), which shows the values of \\(g_s(j-15,\\theta); j = 1,\\ldots,40\\) in the top panel as green circles, and the values of \\(g_s(j-20,\\theta); j = 1,\\ldots,40\\) as purple circles. Note the \\(j-i\\) argument defines \\(Z_i\\) by “shifting” the function forward \\(i\\) integers, and we have shown it for \\(i=15\\) and \\(i=20\\) (with downward arrows). Figure 3.3 also shows simulated values of \\(W_i\\), independent normal random variables with mean zero and variance 1, as gray circles in the middle panel. The resulting simulated \\(Z_i\\), for \\(i = 10,\\ldots,40\\), using (3.3), are shown in the bottom panel. For example, \\(Z_{15}\\) is created by taking the weights given by the green circles, and multiplying each weight times the \\(W_j\\) just below it, and then summing these products, yielding \\(Z_{15}\\). A random variable for each \\(i, i=10,\\ldots,40\\) was created in this way by simply shifting \\(g_s(j-i,\\theta)\\) for each \\(i\\). The random number seed is shown so that you can obtain these exact results. You can also try various sample sizes, different \\(g(j,\\theta)\\), etc., to better understand how moving averages work. Figure 3.3: Moving average function, \\(g_s(j-15,\\theta)\\), operating on W’s, resulting in \\(\\{Z_i\\}\\). 3.1.2 Properties What properties do the moving average functions give to the random variables, \\(\\{Z_i\\}\\), when constructed using (3.3)? If \\(E[W_i] = 0 \\ \\forall \\ i\\), then \\(E[Z_i] = 0\\) for either \\(g(j;\\theta)\\) in (3.4). If the variance of \\(W_i = 1 \\ \\forall \\ i\\), then the variance of \\(Z_i\\) will be \\[\\begin{equation} \\textrm{var}[Z_i] = \\sum_{j = -\\infty}^\\infty [g(j;\\theta)]^2, \\tag{3.5} \\end{equation}\\] and so if \\(\\{Z_i\\}\\) is constructed with \\(g_\\ell(j;\\theta)\\), then \\(\\textrm{var}[Z_i] = 1/\\theta\\). If \\(\\{Z_i\\}\\) is constructed with \\(g_s(j;\\theta)\\), then \\(\\textrm{var}[Z_i] = (2\\theta^2 + 3\\theta + 1)/(6\\theta)\\). Note that we can always construct the random variables with mean \\(0\\) and variance \\(1\\) for \\(W\\), and then add a mean, and scale the newly constructed random variables, afterwards, to obtain any desired mean and variance. The autocovariance between \\(Z_i\\) and \\(Z_{i + h}\\) is \\[\\begin{equation} C(h;\\theta) \\equiv \\textrm{cov}[Z_i, Z_{i + h}] = \\sum_{j = -\\infty}^\\infty g(j;\\theta)g(j - h;\\theta). \\tag{3.6} \\end{equation}\\] Consider \\(g_\\ell(j;\\theta)\\), then \\(C_\\ell(h;\\theta) = (1 - h/\\theta)/\\theta\\). The autocorrelation function is \\[\\begin{equation} \\rho(h;\\theta) \\equiv \\frac{C(h;\\theta)}{\\sqrt{\\textrm{var}(Z_i)\\textrm{var}(Z_{i+h})}}, \\tag{3.7} \\end{equation}\\] so \\(\\rho_\\ell(h;\\theta) = (1 - h/\\theta)\\). A plot of \\(\\rho_\\ell(h;\\theta)\\), for \\(\\theta = 5\\), is rho_ell = function(h, theta){(1 - h/theta)*(h &lt; theta)} par(mar = c(5,5,1,1)) plot(0:6, rho_ell(0:6, 5), pch = 19, cex = 3, cex.lab = 2, cex.axis = 1.5, xlab = &#39;Lag h&#39;, ylab = &#39;Autocorrelation&#39;) Figure 3.4: Theoretical autocorrelation function for \\(\\{Z_i\\}\\). Now compare Figure 3.2 with Figure 3.4. The empirical autocorrelation function on simulated data estimates the theoretical one derived from (3.7). For the moving average function \\(g_s(j;\\theta)\\), the theoretical autocovariance function is \\[ C_s(h,\\theta) = \\frac{(\\theta-h)(\\theta-h+1)(2\\theta + h + 1)}{6\\theta^2} \\] and so the autocorrelation function is \\[ \\rho_s(h,\\theta) = \\frac{(\\theta-h)(\\theta-h+1)(2\\theta + h + 1)}{2\\theta^3 + 3\\theta^2 + \\theta} \\] A plot of \\(\\rho_s(h;\\theta)\\), for \\(\\theta = 5\\), is rho_s = function(h, theta){((theta - h)*(theta - h + 1)* (2*theta + h + 1))*(h &lt; theta)/(2*theta^3 + 3*theta^2 + theta)} par(mar = c(5,5,1,1)) plot(0:6, rho_s(0:6, 5), pch = 19, cex = 3, cex.lab = 2, cex.axis = 1.5, xlab = &#39;Lag h&#39;, ylab = &#39;Autocorrelation&#39;) Figure 3.5: Theoretical autocorrelation function for \\(\\{Z_i\\}\\) when using \\(g_s(h;\\theta)\\). One very important result is that the mean, variance, autocovariance, and autocorrelation functions do not change if the moving average function is translated or flipped. Again consider \\(g_s(j;\\theta)\\) in (3.4), which are the weights given in green in Figure 3.6. Now let \\[ g_{s1}(j;\\theta) = \\left(\\frac{j}{\\theta}\\right) \\mathcal{I}(0 \\le j \\le \\theta) \\\\ g_{s2}(j;\\theta) = \\left(1-\\frac{|j|}{\\theta}\\right) \\mathcal{I}(0 \\le j \\le \\theta). \\] Let’s create these functions in R, g_s1 = function(j, theta){(j/theta)*(0 &lt;= j &amp; j &lt;= theta)} g_s2 = function(j, theta){(1-abs(j)/theta)*(0 &lt;= j &amp; j &lt;= theta)} For \\(g_{s1}(j;\\theta)\\), the moving average function is translated from \\(g_{s}(j;\\theta)\\) to the integers with positive values. For example, Figure 3.6 shows \\(g_{s}(j-15;\\theta)\\) as green circles, which are exactly the same as in Figure 3.3). For \\(g_{s1}(j-15;\\theta)\\), whose weights are shown as purple circles in Figure 3.6, the moving average function \\(g_{s}(j;\\theta)\\) has been translated to the right (yet still defines \\(Z_{15}\\)). Although the simulated \\(Z_15\\) will obviously be different, the mean, variance, autocovariance, and autocorrelation are exactly the same for \\(g_{s}(j;\\theta)\\) and \\(g_{s1}(j;\\theta)\\). The same is true if \\(g_{s}(j;\\theta)\\) is flipped. For \\(g_{s2}(j-15;\\theta)\\), whose weights are shown as gold circles in Figure 3.6, the moving average function \\(g_{s}(j;\\theta)\\) has been flipped (yet again defines \\(Z_{15}\\)). The statistical properties of \\(\\{Z_i\\}\\) are the same for all 3 of the moving average functions shown in Figure 3.6. This is interesting because we will see that translation and flipping matter for stream networks. Figure 3.6: Three moving average functions – \\(g_s(j-15;\\theta)\\) in green, \\(g_{s1}(j-15;\\theta)\\) in purple, and \\(g_{s2}(j-15;\\theta)\\) in gold – that yield the same mean, variance, autocovariance, and autocorrelation. 3.2 Continuous Time Series Now, let us extend what we learned in Section 3.1 to continuous time. 3.2.1 Definition and Construction Yaglom (1987) shows that a large class of autocovariances can be developed by creating random variables as the integration of a moving-average function over a white-noise random process, \\[\\begin{equation} Z(s) = \\int_{-\\infty}^{\\infty}g(x-s;\\boldsymbol{\\theta})dW(x), \\tag{3.8} \\end{equation}\\] where \\(x\\) and \\(s\\) are locations on the real line and \\(g(x;\\boldsymbol{\\theta})\\) is called the moving-average function defined on \\(\\mathcal{R}^{1}\\). Equation (3.8) looks a little intimidating, but we can break it down and rely on what we learned in Section 3.1. First, \\(g(x;\\boldsymbol{\\theta})\\) is defined on continuous \\(x\\), but otherwise is exactly analogous to (3.2), which was defined on the integers. Next, consider \\(dW(x)\\), which is a “Brownian motion differential.” First, look again at (3.3) and remove the stipulation that \\(g(j;\\theta)\\) is defined on integers, and replace it with \\(g(x;\\theta)\\) that is now defined on a regular sequence on the real line. Then imagine that we start making that sequence finer and finer, packing more and more \\(W_i\\) per unit of length. If the definition of \\(g(x;\\theta)\\) stays constant, then the variance will grow and grow because we are summing more and more \\(W_i\\). In order to get to a continuous version of \\(W_i\\), their variances must shrink as we pack them tighter and tighter. Althought the mathematics are deep and intricate, for practical purposes we can think of \\(dW(x)\\) as the continuous analog to \\(W_i\\) where they get very dense and their variances shrink in just the right way. In the same way, the integral \\(\\int\\) in (3.8) simply replaces the \\(\\sum\\) in (3.3). If it is simpler, one can just think of (3.8) as a limit as (3.3) gets really dense within an area (that is, the \\(\\infty\\)-limits of (3.3) are within a interval on the real line, rather than on the integers). Hence, the construction of moving averages for continuous time is a complete analog to discrete time. The result is that we have a random function rather than a finite set of random variables. This is shown by the notation that \\(Z(s)\\) is a function, defined everywhere on the real line; that is, at any \\(s \\in \\mathcal{R}^1\\). What do some of these moving average functions, \\(g(x;\\boldsymbol{\\theta})\\), look like? A set of 5 of them, which will carry over to stream networks, is given in Table 3.1. Table 3.1: Moving average functions. Name Moving average function Linear-with-sill \\(g_{lws}(x;\\boldsymbol{\\theta}) = \\theta_p \\mathcal{I}(0 \\leq x/\\theta_r \\leq 1)\\) Spherical \\(g_{sph}(x;\\boldsymbol{\\theta}) = \\theta_p(1 - x/\\theta_r) \\mathcal{I}(0 \\leq x/\\theta_r \\leq 1)\\) Epanechnikov \\(g_{epa}(x;\\boldsymbol{\\theta}) = \\theta_p(1 - x/\\theta_r)^2 \\mathcal{I}(0 \\leq x/\\theta_r \\leq 1)\\) Exponential \\(g_{exp}(x;\\boldsymbol{\\theta}) = \\theta_pe^{-x/\\theta_r} I(0 \\leq x)\\) Mariah \\(g_{mar}(x;\\boldsymbol{\\theta}) = \\theta_p\\frac{1}{1 + x/\\theta_r } I(0 \\leq x)\\) In R, we create each function, g_lws = function(x, theta){(1)*(0 &lt;= x &amp; x &lt;= 1)} g_sph = function(x, theta){(1-x/theta)*(0 &lt;= x &amp; x &lt;= theta)} g_epa = function(x, theta){(1-x/theta)^2*(0 &lt;= x &amp; x &lt;= theta)} g_exp = function(x, theta){exp(-x/theta)*(0 &lt;= x)} g_mar = function(x, theta){1/(1 + x/theta)*(0 &lt;= x)} A graph of each function is given in Figure 3.7 for \\(\\theta_p = 1\\) and \\(\\theta_r = 1\\). Figure 3.7: la te da To help visualize the construction of \\(Z(s)\\) in (3.8), we provide Figure 3.8 as the continuous version of Figure 3.3. The weights are provided in the top panel of Figure 3.8. Note that the constructions at locations \\(x = 0.1\\) and \\(x = 0.2\\), shown in green, the weights are only forward of \\(Z(0.1)\\) and \\(Z(0.2)\\), respectively. The product of these weights and white noise, \\(dW(x)\\), are integrated to provide the random value. We do not show any units for \\(dW(x)\\) because they are infinitesimally small (and infinitely dense). We do not show any units for \\(Z(x)\\) because it can be scaled to any variance, and we show more about its properties in the next section. Note that \\(Z(x)\\) is continuous, so it is a random function, shown in green for \\(g_{sph}(x,\\theta)\\) when the weights are forward. When we flip the weights around, so that they point backward, as shown by the purple functions in the top panel, we obtain an mirror image of the random function (for fixed \\(dW(x)\\)) as the purple function in the bottom panel. The consequence of flipping the function will be discussed in the next section. Figure 3.8: Moving average function, \\(g_{sph}(x-s,\\theta)\\), integrated against dW(x), resulting in Z(x). We show the construction for x = 0.1, 0.2, 0.8, and 0.9. For x = 0.1, 0.2, colored in green, the weights are only forward from the location of the constructed random variable. For x = 0.8, 0.9, colored in purple, the weights are only backward from the location of the constructed random varible. 3.2.2 Properties Now, what about properties of the construction in (3.8)? In Section 3.1.2 we showed the expectation, variance, autocovariance, and autocorrelation for discrete time series under a moving average construction. Generally, white noise is assumed to have mean 0, so \\[ \\textrm{E}[Z(s)] = 0. \\] The variance is \\[\\begin{equation} \\textrm{var}[Z(s)] = E[Z(s)^2]=\\int_{-\\infty}^{\\infty}g(x;\\boldsymbol{\\theta})^2dx. \\tag{3.9} \\end{equation}\\] Notice that for the variance to exist, (3.9) must exist; in other words, \\(g(x;\\boldsymbol{\\theta})\\) must not have too much area under the curve. This condition is often stated by saying that \\(g(x;\\boldsymbol{\\theta})\\) is “square integrable.” What about the autocovariance and autocorrelation? The moving-average construction (3.8) allows a valid autocovariance between \\(Z(s)\\) and \\(Z(s+h)\\) to be expressed as \\[\\begin{equation} C(h;\\boldsymbol{\\theta})= \\int_{j = -\\infty}^{\\infty}g(x;\\boldsymbol{\\theta})g(x-h;\\boldsymbol{\\theta})dx. \\tag{3.10} \\end{equation}\\] Once again, compare (3.10) with (3.6) from discrete time series. 3.3 Tail-up Models The moving average construction in (3.8) and (3.10) is well-known for the continuous real line from \\(-\\infty\\) to \\(\\infty\\), such as for time-series models. Ver Hoef, Peterson, and Theobald (2006) and Cressie et al. (2006) use moving averages for a stream network to develop models as in Figure 3.9. Figure 3.9: Three locations on a stream network, \\(r_1\\), \\(s_2\\), \\(t_3\\). The tail-up moving-average functions are shown each location. The moving average functions are integrated against white noise on a stream network, which is depicted as the ragged black lines on the stream network, given as blue lines. Autocorrelation is created when functions overlap. The total area under the green function, going upstream from \\(r_1\\), is constant, requiring a splitting of the function up each branch. We call these the ``tail-up’’ models because they are unilateral in the upstream direction (moving average function values are positive only upstream from a location). In Figure , the moving average function goes upstream from \\(r_1\\). When it reaches a fork, at \\(u_1\\), the function continues up each branch, but it is weighted. For example, weights could be proportional to flow volume or other meaningful metrics. For the following development, let \\(r_i\\) and \\(s_j\\) denote two locations on a stream network, and let \\(h\\) be the stream distance between them. For FC locations, from (3.8), the unweighted covariance between two such locations is \\[\\begin{equation} C_t(h;\\boldsymbol{\\theta}) = \\int_{h}^{\\infty}g(x;\\boldsymbol{\\theta})g(x-h;\\boldsymbol{\\theta})dx, \\tag{3.11} \\end{equation}\\] where \\(h\\) is the stream distance between locations \\(r_i\\) and \\(s_j\\). As mentioned earlier, a unique feature of tail-up stream network models is the splitting of \\(g(x;boldsymbol{\\theta})\\) as it goes upstream (Figure 3.9, which is achieved by assigning a weighting attribute to each stream segment. To account for the splitting (Ver Hoef, Peterson, and Theobald 2006; Cressie et al. 2006), (3.8) is modified to construct a spatial process on a stream network as \\[ Z(s_i;\\boldsymbol{\\theta}) = \\int_{\\vee_{s_i}} g(x-s_i;\\boldsymbol{\\theta}) \\sqrt{\\frac{\\Omega(x)}{\\Omega(s_i)}} dW(x), \\] where \\(\\Omega(x)\\) is an additive function that ensures stationarity in variance; that is, \\(\\Omega(x)\\) is constant within a stream segment, but then \\(\\Omega(x)\\) is the sum of each segment’s value when two segments join at a junction. (Figure ). This definition leads to (3.12) where \\(\\pi_{i,j}=\\sqrt{\\Omega(s_j)/\\Omega(r_i)}\\). If two sites are FU, then their covariance is zero, by construction (Figure 3.9. Then the following tail-down covariance models have been developed using the moving average construction (Ver Hoef, Peterson, and Theobald 2006): \\[\\begin{equation} C_u(r_i,s_j|\\boldsymbol{\\theta}_u)= \\left\\{ \\begin{array}{ll} \\pi_{i,j}C_t(h;\\boldsymbol{\\theta}_u) &amp; \\textrm{if $r_i$ and $s_j$ FC,} \\\\ 0 &amp; \\textrm{if $r_i$ and $s_j$ FU,} \\end{array} \\right. \\tag{3.12} \\end{equation}\\] where \\(\\pi_{i,j}\\) are weights due to branching characteristics of the stream, and the function \\(C_t(h;\\boldsymbol{\\theta}_u)\\) can take the following forms: we obtain the following tail-up models. Tail-up Linear-with-Sill Model: \\[ C_t(h;\\boldsymbol{\\theta}_u)= \\sigma^2_u\\left(1 -\\frac{h}{\\theta_r}\\right)\\mathcal{I}\\left(\\frac{h}{\\theta_r}\\leq 1\\right). \\] Tail-up Spherical Model, \\[ C_t(h;\\boldsymbol{\\theta}_u)= \\sigma^2_u\\left(1-\\frac{3}{2}\\frac{h}{\\alpha_u}+\\frac{1}{2}\\frac{h^3}{\\alpha_u^3}\\right) I\\left(\\frac{h}{\\alpha_u}\\leq 1\\right), \\] Tail-Up Exponential Model, \\[ C_t(h;\\boldsymbol{\\theta}_u)= \\sigma^2_u\\exp(-3h/\\alpha_u), \\] Tail-up Mariah Model, \\[ C_t(h;\\boldsymbol{\\theta}_u)= \\left\\{ \\begin{array}{ll} \\sigma^2_u\\left(\\frac{\\log(90h/\\alpha_u+1)}{90h/\\alpha_u}\\right) &amp; \\textrm{if} \\; h &gt; 0,\\\\ \\sigma^2_u &amp; \\textrm{if} \\; h = 0,\\\\ \\end{array} \\right. \\] Tail-up Epanechnikov Model , \\[ C_t(h;\\boldsymbol{\\theta}_u)= \\frac{\\sigma^2_u(h-\\alpha_u)^2f_{eu}(h;\\alpha_u)}{16\\alpha_u^5} I\\left(\\frac{h}{\\alpha_u}\\leq 1\\right), \\] where \\(f_{eu}(h;\\alpha_u)=16\\alpha_u^2 + 17\\alpha_u^2h - 2\\alpha_uh^2-h^3\\), \\(I(\\cdot)\\) is the indicator function (equal to one when the argument is true), \\(\\sigma^2_u &gt; 0\\) is an overall variance parameter (also known as the partial sill), \\(\\alpha_u &gt; 0\\) is the range parameter, and \\(;\\boldsymbol{\\theta}_u = (\\sigma^2_u,\\alpha_u)^\\top\\). Note the factors 3, and 90 for the exponential and Mariah models, respectively, which cause the autocorrelation to be approximately 0.05 when \\(h\\) equals the range parameter, which helps compare range parameters (\\(\\alpha_u\\)) across models. (The distance at which autocorrelation reaches 0.05 is sometimes called the effective range when models approach zero asymptotically.) 3.4 Tail-Down Models The moving average construction in (3.8) and (3.10) is well-known for the continuous real line from \\(-\\infty\\) to \\(\\infty\\), such as for time-series models. For tail-down models, we also distinguish between the FC and FU situation. When two sites are FU, recall that \\(b\\) denotes the longer of the distances to the common downstream junction, and \\(a\\) denotes the shorter of the two distances. Then the model is the integral of the overlapping moving average functions seen in Figure 3.10. Figure 3.10: Three locations on a stream network, \\(r_1\\), \\(s_2\\), \\(t_3\\). The tail-up moving-average functions are shown each location. The moving average functions are integrated against white noise on a stream network, which is depicted as the ragged black lines on the stream network, given as blue lines. Autocorrelation is created when functions overlap. The total area under the green function, going upstream from \\(r_1\\), is constant, requiring a splitting of the function up each branch. If two sites are FC, again use \\(h\\) to denote their total separation distance via the stream network, and the model is the integral of the overlapping moving average functions seen in Figure 3.10. The following are tail-down models: Tail-Down Linear-with-Sill Model, \\(b \\geq a \\geq 0\\), \\[ C_{d,lws}(a,b,h;\\boldsymbol{\\theta})= \\left\\{ \\begin{array}{ll} \\theta_p\\left(1 -\\frac{h}{\\theta_r}\\right)I\\left(\\frac{h}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FC,}\\\\ \\theta_p\\left(1 -\\frac{b}{\\theta_r}\\right)I\\left(\\frac{b}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FU,} \\end{array} \\right. \\] Tail-Down Spherical Model, \\(b \\geq a \\geq 0\\), \\[ C_{d,sph}(a,b,h;\\boldsymbol{\\theta})= \\left\\{ \\begin{array}{ll} \\theta_p(1-\\frac{3}{2}\\frac{h}{\\theta_r}+\\frac{1}{2}\\frac{h^3}{\\theta_r^3})I\\left(\\frac{h}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FC,}\\\\ \\theta_p\\left(1-\\frac{3}{2}\\frac{a}{\\theta_r}+\\frac{1}{2}\\frac{b}{\\theta_r}\\right) \\left(1- \\frac{b}{\\theta_r}\\right)^2I\\left(\\frac{b}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FU,} \\end{array} \\right. \\] Tail-down Epanechnikov Model, \\(b \\geq a \\geq 0\\), \\[ C_{d,epa}(a,b,h;\\boldsymbol{\\theta})= \\left\\{ \\begin{array}{ll} \\frac{\\theta_p(h-\\theta_r)^2f_{eu}(h;\\theta_r)}{16\\theta_r^5} I\\left(\\frac{h}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FC,}\\\\ \\frac{\\theta_p(b-\\theta_r)^2f_{ed}(a,b;\\theta_r)}{16\\theta_r^5} I\\left(\\frac{b}{\\theta_r}\\leq 1\\right) &amp; \\textrm{if FU,} \\end{array} \\right. \\] where \\(f_{eu}\\) was defined for tail-up models, and \\[ f_{ed}(a,b;\\theta_r)=16\\theta_r^3 + 17\\theta_r^2b - 15\\theta_ra - 20\\theta_ra^2 - \\\\ 2\\theta_rb^2 + 10\\theta_rab + 5ab^2 - b^3 - 10ba^2. \\] Tail-down Exponential Model, \\[ C_{d,exp}(a,b,h;\\boldsymbol{\\theta})= \\left\\{ \\begin{array}{ll} \\theta_p\\exp(-3h/\\theta_r) &amp; \\textrm{if FC,}\\\\ \\theta_p\\exp(-3(a+b)/\\theta_r) &amp; \\textrm{if FU,} \\end{array} \\right. \\] Tail-down Mariah Model, \\[ C_{d,mar}(a,b,h;\\boldsymbol{\\theta})= \\left\\{ \\begin{array}{ll} \\sigma^2\\left(\\frac{\\log(90h/\\theta_r+1)}{90h/\\theta_r}\\right) &amp; \\textrm{if FC, } h &gt; 0,\\\\ \\sigma^2 &amp; \\textrm{if FC, } h = 0,\\\\ \\sigma^2\\left(\\frac{\\log(90a/\\theta_r+1)-\\log(90b/\\theta_r+1)}{90(a-b)/\\theta_r}\\right) &amp; \\textrm{if FU, } a \\ne b, \\\\ \\sigma^2\\left(\\frac{1}{90a/\\theta_r+1}\\right) &amp; \\textrm{if FU, } a = b, \\end{array} \\right. \\] For all models, \\(\\sigma^2 &gt; 0\\) and \\(\\theta_r &gt; 0\\), and \\(\\boldsymbol{\\theta} = (\\sigma^2,\\theta_r)^\\top\\). Although not necessary to maintain stationarity, the weights used in the tail-up models can be applied to the tail-down models as well. Note that \\(h\\) is unconstrained, because for model-building we imagine that the headwater and outlet segments continue to infinity, as first described by . Also note that \\(a\\) does not appear in the tail-down linear-with-sill model, but is used indirectly because the model depends on the point that is farthest from the junction; i.e., \\(b\\), and so \\(a\\) is the shorter of the two distances. 3.5 Euclidean Distance Models We also include the possibility for traditional geostatistical models based on Euclidean distance. Before developing the spatial linear model, we give the Euclidean distance models that we have included in the SSN package for R. We allow the use of 4 Euclidean distance models in the SSN package. Let \\(d\\) be Euclidean distance. Then we have the follow autocovariance functions Spherical Model, \\[ C_{e,sph}(d;\\boldsymbol{\\theta})= \\sigma_e^2\\left(1-\\frac{3}{2}\\frac{d}{\\theta_r}+\\frac{1}{2}\\frac{d^3}{\\theta_r^3}\\right)\\mathcal{I}\\left(\\frac{d}{\\theta_r}\\leq 1\\right) \\] Exponential Model, \\[ C_{e,exp}(d;\\boldsymbol{\\theta})= \\sigma_e^2\\exp(-3d/\\theta_r) \\] References "],
["spatial-linear-model.html", "Chapter 4 Spatial Linear Model 4.1 Variance Components 4.2 Semivariograms 4.3 Estimation 4.4 Prediction 4.5 Model Diagnostics", " Chapter 4 Spatial Linear Model The moving average constructions, creating spatially-autocorrelated random variables on stream networks, as developed in Chapter 3, are part of a larger strategy. We use them as random errors in a spatial linear model. 4.1 Variance Components The most general linear model that we consider is \\[\\begin{equation} \\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{z}_u + \\mathbf{z}_d +\\mathbf{z}_e + \\mathbf{W}_1\\boldsymbol{\\gamma}_1 + \\ldots + \\mathbf{W}_p\\boldsymbol{\\gamma}_p + \\boldsymbol{\\epsilon}, \\tag{4.1} \\end{equation}\\] where \\(\\mathbf{X}\\) is a design matrix of fixed effects and \\(\\boldsymbol{\\beta}\\) is a vector of parameters. The vector \\(\\mathbf{z}_u\\) contains spatially-autocorrelated random variables with a tail-up autocovariance, with \\(\\textrm{var}(\\mathbf{z}_u) = \\sigma_u^2\\mathbf{R}(\\theta_r)\\), where \\(\\mathbf{R}(\\theta_r)\\) is a correlation matrix that depends on the range parameter \\(\\theta_r\\) as described in Section 3.3. The vector \\(\\mathbf{z}_d\\) contains spatially-autocorrelated random variables with a tail-down autocovariance, \\(\\textrm{var}(\\mathbf{z}_d) = \\sigma^2\\mathbf{R}(\\theta_r)\\) as described in Section 3.4. The vector \\(\\mathbf{z}_e\\) contains spatially-autocorrelated random variables with a Euclidean distance autocovariance, \\(\\textrm{var}(\\mathbf{z}_e) = \\sigma_e^2\\mathbf{R}(\\theta_r)\\) as described below. We can include non-spatial random effects, where \\(\\mathbf{W}_k\\) is a design matrix for random effects \\(\\boldsymbol{\\gamma}_k; k = 1,\\ldots,p\\) with \\(\\textrm{var}(\\boldsymbol{\\gamma}_k)=\\sigma^2_k\\mathbf{I}\\), and \\(\\boldsymbol{\\epsilon}\\) contains independent random variables with \\(\\textrm{var}(\\boldsymbol{\\epsilon})=\\sigma^2_0\\mathbf{I}\\). When used for spatial prediction, this model is referred to as “universal”&quot; kriging (Le and Zidek 2006, pg. 107) , with “ordinary”&quot; kriging being the special case where the design matrix \\(\\mathbf{X}\\) is a single column of ones (Cressie 1993, pg. 119). The most general covariance matrix we form is, \\[\\begin{equation} \\begin{array}{c} \\textrm{cov}(\\mathbf{Y})=\\boldsymbol{\\Sigma}=\\sigma_u^2\\mathbf{R}(\\theta_r) + \\sigma_d^2\\mathbf{R}(\\alpha_d) + \\sigma_e^2\\mathbf{R}(\\alpha_e) + \\\\ \\sigma_1^2\\mathbf{W}_1\\mathbf{W}_1^\\top + \\ldots + \\sigma_p^2\\mathbf{W}_p\\mathbf{W}_p^\\top + \\sigma_0^2\\mathbf{I}. \\end{array} \\tag{4.2} \\end{equation}\\] 4.2 Semivariograms 4.3 Estimation 4.3.1 Quasi Models 4.4 Prediction 4.4.1 Block Prediction 4.5 Model Diagnostics References "],
["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
